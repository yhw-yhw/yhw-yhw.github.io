<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hongwei yi</title>
  
  <meta name="author" content="Hongwei Yi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hongwei Yi</name>
              </p>
              



              <p>I am a PhD student (2020.09-) at the <a href="https://ps.is.tuebingen.mpg.de">Perceiving Systems Department of Max Planck Institute for Intelligent Systems</a>, jointly supervised by <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael J. Black</a> and <a href="https://vlg.inf.ethz.ch/people/person-detail.siyutang.html">Siyu Tang</a>. 
                Before that, I achieved my M.S. in computer applied technology from <a href="http://english.pku.edu.cn/">Peking University</a> in 2020.07 and earned my B.S. in computer science and technology from <a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications</a>in 2017.07. 
              </p>
              
              <p>My main research focus is understanding our 3D world with computer vision and machine learning, including 3D human (face reconstruction, mark-less motion capture, motion reconstruction/modeling/generation/prediction), 3D scene reconstruction (Multi-View Stereo), and human-scene interaction. 
              </p>
              <p style="text-align:center">
                <a href="mailto:hongwei.yi@tuebingen.mpg.de">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://www.linkedin.com/in/%E9%B8%BF%E4%BC%9F-%E6%98%93-758590195/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=ocMf7fQAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/HongweiYi2">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/yhw-yhw">Github</a> &nbsp/&nbsp
                <a href="https://www.dropbox.com/s/gpb21lc9pgq66yx/hwyi_cv.pdf?dl=0">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/hongwei.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/hongwei.png" class="hoverZoomLink"></a>
            </td>
          </tr>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication</heading>
              <!-- <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
             <!-- #onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0"> -->
            <!-- <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mip360_sat.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mip360_sat.jpg' width="160">
              </div>
              <script type="text/javascript">
                function mip360_start() {
                  document.getElementById('mip360_image').style.opacity = "1";
                }

                function mip360_stop() {
                  document.getElementById('mip360_image').style.opacity = "0";
                }
                mip360_stop()
              </script>
            </td> -->
            
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/pvamvsnet.png" alt="prl" width="160" height="160">
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Pyramid Multi-view Stereo Net with Self-adaptive View Aggregation</papertitle>
              </a>
              <br>
              <strong>Hongwei Yi*</strong>,
              <a href="https://www.researchgate.net/profile/Zizhuang-Wei">Zizhuang Wei*</a>,
              <a href="https://dingmyu.github.io/">Mingyu Ding</a>,
              <a href="https://scholar.google.com/citations?user=o41-Nj8AAAAJ&hl=ja">Runze Zhang</a>,

              <a href="https://eecs.pku.edu.cn/info/1502/6740.htm">Yisong Chen</a>,
              <a href="https://eecs.pku.edu.cn/info/1502/6725.htm">Guoping Wang</a>,
              <a href="http://scholar.google.com/citations?user=nFhLmFkAAAAJ&hl=zh-CN">Yu-Wing Tai</a>
              (* denotes equal contribution)
              <br>
							<em>ECCV</em>, 2020
              <br>
              <!-- <a href="http://jonbarron.info/mipnerf360">project page</a> -->
              <!-- / -->
              <a href="https://github.com/yhw-yhw/PVAMVSNet">code</a>
              /
              <a href="https://arxiv.org/pdf/1912.03001.pdf">arXiv</a>
              /
              <!-- <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
              <p></p>
              <!-- <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p> -->
            </td>
          </tr> 


          <tr>
            <!-- #onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0"> -->
           <!-- <td style="padding:20px;width:25%;vertical-align:middle">
             <div class="one">
               <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
               <source src="images/mip360_sat.mp4" type="video/mp4">
               Your browser does not support the video tag.
               </video></div>
               <img src='images/mip360_sat.jpg' width="160">
             </div>
             <script type="text/javascript">
               function mip360_start() {
                 document.getElementById('mip360_image').style.opacity = "1";
               }

               function mip360_stop() {
                 document.getElementById('mip360_image').style.opacity = "0";
               }
               mip360_stop()
             </script>
           </td> -->
           
           <td style="padding:20px;width:25%;vertical-align:middle">
             <img src="images/d2hcmvsnet.png" alt="prl" width="160" height="160">
           </td>

           <td style="padding:20px;width:75%;vertical-align:middle">
             <a href="">
               <papertitle>Dense Hybrid Recurrent Multi-view Stereo Net with Dynamic Consistency Checking</papertitle>
             </a>
             <br>
             <a href="https://openreview.net/profile?id=~Jianfeng_Yan1">Jianfeng Yan*</a>,
             <strong>Hongwei Yi*</strong>,
             <a href="https://www.researchgate.net/profile/Zizhuang-Wei">Zizhuang Wei*</a>,
             <a href="https://dingmyu.github.io/">Mingyu Ding</a>,
             <a href="https://pratulsrinivasan.github.io/">Runze Zhang</a>,
             <a href="https://eecs.pku.edu.cn/info/1502/6740.htm">Yisong Chen</a>,
             <a href="https://eecs.pku.edu.cn/info/1502/6725.htm">Guoping Wang</a>,
             <a href="http://scholar.google.com/citations?user=nFhLmFkAAAAJ&hl=zh-CN">Yu-Wing Tai</a>
             (* denotes equal contribution)
             <br>
             <em>ECCV</em>, 2020
             <br>
             <!-- <a href="http://jonbarron.info/mipnerf360">project page</a> -->
             <!-- / -->
             <a href="https://github.com/yhw-yhw/D2HC-RMVSNet">code</a>
             /
             <a href="https://arxiv.org/abs/2007.10872">arXiv</a>
             /
             <!-- <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
             <p></p>
             <!-- <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p> -->
           </td>
         </tr> 

         <tr>
          <!-- #onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0"> -->
         <!-- <td style="padding:20px;width:25%;vertical-align:middle">
           <div class="one">
             <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
             <source src="images/mip360_sat.mp4" type="video/mp4">
             Your browser does not support the video tag.
             </video></div>
             <img src='images/mip360_sat.jpg' width="160">
           </div>
           <script type="text/javascript">
             function mip360_start() {
               document.getElementById('mip360_image').style.opacity = "1";
             }

             function mip360_stop() {
               document.getElementById('mip360_image').style.opacity = "0";
             }
             mip360_stop()
           </script>
         </td> -->
         
         <td style="padding:20px;width:25%;vertical-align:middle">
           <img src="images/segvoxelnet.png" alt="prl" width="160" height="160">
         </td>

         <td style="padding:20px;width:75%;vertical-align:middle">
           <a href="">
             <papertitle>SegVoxelNet: Exploring Semantic Context and Depth-aware Features for 3D Vehicle Detection from Point Cloud</papertitle>
           </a>
           <br>
           <strong>Hongwei Yi</strong>,
           <a href="https://shishaoshuai.com/">Shaoshuai Shi</a>,
           <a href="https://dingmyu.github.io/">Mingyu Ding</a>,
           <a href="https://scholar.google.com.hk/citations?user=726MCb8AAAAJ&hl=en">Jiankai Sun</a>,
           <a href="https://scholar.google.com/citations?user=Hhpry4kAAAAJ&hl=en">Kui Xu</a>,
           <a href="https://scholar.google.com/citations?user=i35tdbMAAAAJ&hl=zh-CN">Hui Zhou</a>, 
           <a href="https://wang-zhe.me/">Zhe Wang</a>,
           <a href="https://eecs.pku.edu.cn/info/1502/6732.htm">Sheng Li</a>,
           <a href="https://eecs.pku.edu.cn/info/1502/6725.htm">Guoping Wang</a>,
           <br>
           <em>ICRA</em>, 2020
           <br>
           <!-- <a href="http://jonbarron.info/mipnerf360">project page</a> -->
           <!-- / -->
           <a href="https://arxiv.org/abs/2002.05316">arXiv</a>
           /
           <!-- <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
           <p></p>
           <!-- <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p> -->
         </td>
       </tr> 

       <tr>
        <!-- #onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0"> -->
       <!-- <td style="padding:20px;width:25%;vertical-align:middle">
         <div class="one">
           <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
           <source src="images/mip360_sat.mp4" type="video/mp4">
           Your browser does not support the video tag.
           </video></div>
           <img src='images/mip360_sat.jpg' width="160">
         </div>
         <script type="text/javascript">
           function mip360_start() {
             document.getElementById('mip360_image').style.opacity = "1";
           }

           function mip360_stop() {
             document.getElementById('mip360_image').style.opacity = "0";
           }
           mip360_stop()
         </script>
       </td> -->
       
       <td style="padding:20px;width:25%;vertical-align:middle">
         <img src="images/arieal_seman.png" alt="prl" width="160" height="160">
       </td>

       <td style="padding:20px;width:75%;vertical-align:middle">
         <a href="">
           <papertitle>Semantic 3D Reconstruction with Learning MVS and 2D Segmentation of Aerial Images</papertitle>
         </a>
         <br>
         <a href="https://www.vis.uni-stuttgart.de/institut/team/Wang-00053/">Yao Wang</a>,
         <a href="https://www.researchgate.net/profile/Zizhuang-Wei">Zizhuang wei</a>,
         <strong>Hongwei Yi</strong>,
         <a href="https://eecs.pku.edu.cn/info/1502/6740.htm">Yisong Chen</a>,
         <a href="https://eecs.pku.edu.cn/info/1502/6725.htm">Guoping Wang</a>,
         <br>
         <em>Applied Sciences</em>, 2020
         <br>
         <!-- <a href="http://jonbarron.info/mipnerf360">project page</a> -->
         <!-- / -->
         <a href="https://www.mdpi.com/2076-3417/10/4/1275/pdf">arXiv</a>
         /
         <!-- <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
         <p></p>
         <!-- <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p> -->
       </td>
     </tr> 
        
     <tr>
      <!-- #onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0"> -->
     <!-- <td style="padding:20px;width:25%;vertical-align:middle">
       <div class="one">
         <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
         <source src="images/mip360_sat.mp4" type="video/mp4">
         Your browser does not support the video tag.
         </video></div>
         <img src='images/mip360_sat.jpg' width="160">
       </div>
       <script type="text/javascript">
         function mip360_start() {
           document.getElementById('mip360_image').style.opacity = "1";
         }

         function mip360_stop() {
           document.getElementById('mip360_image').style.opacity = "0";
         }
         mip360_stop()
       </script>
     </td> -->
     
     <td style="padding:20px;width:25%;vertical-align:middle">
       <img src="images/depth_wise_3DOD.png" alt="prl" width="160" height="160">
     </td>

     <td style="padding:20px;width:75%;vertical-align:middle">
       <a href="">
         <papertitle>Learning Depth-Guided Convolutions for Monocular 3D Object</papertitle>
       </a>
       <br>
       <a href="https://dingmyu.github.io/">Mingyu Ding</a>,
       <a href="https://www.researchgate.net/profile/Yuqi-Huo-3">Yuqi Huo</a>,
       <strong>Hongwei Yi</strong>,
       <a href="https://wang-zhe.me/">Zhe Wang</a>,
       <a href="https://shijianping.me/">Jianping Shi</a>,
       <a href="https://sites.google.com/site/zhiwulu/">Zhiwu Lu</a>,
       <a href="http://luoping.me/">Ping Luo</a>,
       <br>
       <em>CVPR</em>, 2020
       <br>
       <!-- <a href="http://jonbarron.info/mipnerf360">project page</a> -->
       <!-- / -->
       <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Ding_Learning_Depth-Guided_Convolutions_for_Monocular_3D_Object_Detection_CVPR_2020_paper.pdf">arXiv</a>
       /
       <!-- <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
       <p></p>
       <!-- <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p> -->
     </td>
   </tr> 

   <tr>
    <!-- #onmouseout="mip360_stop()" onmouseover="mip360_start()"  bgcolor="#ffffd0"> -->
   <!-- <td style="padding:20px;width:25%;vertical-align:middle">
     <div class="one">
       <div class="two" id='mip360_image'><video  width=100% height=100% muted autoplay loop>
       <source src="images/mip360_sat.mp4" type="video/mp4">
       Your browser does not support the video tag.
       </video></div>
       <img src='images/mip360_sat.jpg' width="160">
     </div>
     <script type="text/javascript">
       function mip360_start() {
         document.getElementById('mip360_image').style.opacity = "1";
       }

       function mip360_stop() {
         document.getElementById('mip360_image').style.opacity = "0";
       }
       mip360_stop()
     </script>
   </td> -->
   
   <td style="padding:20px;width:25%;vertical-align:middle">
     <img src="images/MMFace.png" alt="prl" width="160" height="160">
   </td>

   <td style="padding:20px;width:75%;vertical-align:middle">
     <a href="">
       <papertitle>MMFace: A multi-metric regression network for unconstrained face reconstruction</papertitle>
     </a>
     <br>
     <strong>Hongwei Yi</strong>,
     <a href="https://scholar.google.com/citations?user=WDJL3gYAAAAJ&hl=zh-CN">Chen Li</a>,
     <a href="https://scholar.google.co.uk/citations?user=JYtbNBsAAAAJ&hl=en">Qiong Cao</a>,
     
     <a href="http://scholar.google.com/citations?user=PeMuphgAAAAJ&hl=zh-CN">Xiaoyong Shen</a>,
     <a href="https://eecs.pku.edu.cn/info/1502/6732.htm">Sheng Li</a>,
     <a href="https://eecs.pku.edu.cn/info/1502/6725.htm">Guoping Wang</a>,
     <a href="http://scholar.google.com/citations?user=nFhLmFkAAAAJ&hl=zh-CN">Yu-Wing Tai</a>,
     <br>
     <em>CVPR</em>, 2019
     <br>
     <!-- <a href="http://jonbarron.info/mipnerf360">project page</a> -->
     <!-- / -->
     <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yi_MMFace_A_Multi-Metric_Regression_Network_for_Unconstrained_Face_Reconstruction_CVPR_2019_paper.pdf">arXiv</a>
     /
     <!-- <a href="https://youtu.be/zBSH-k9GbV4">video</a> -->
     <p></p>
     <!-- <p>mip-NeRF can be extended to produce realistic results on unbounded scenes.</p> -->
   </td>
 </tr> 

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Academic Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td> -->
            <td width="100%" valign="center">
              <strong>Conference Reviewer:</strong> CVPR22, ICCV21, 3DV20.
              <br>
              <strong>Journal Reviewer:</strong> Computers & Graphics.
              <br>
            </td>
          </tr>
          
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                The template is borrowed from <a href="https://github.com/jonbarron/jonbarron_website">this awesome website</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
